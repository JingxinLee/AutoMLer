(papers) root@PPGod-PC:~/paper/mypaper_code/automl/tasks/blood-transfusion-service-center# /root/anaconda3/envs/papers/bin/python /root/paper/mypaper_code/automl/tasks/blood-transfusion-service-center/ag_bank_auth.py
   V1  V2      V3  V4  target
0   9  11  2750.0  49       2
1   2  12  3000.0  95       1
2   4  20  5000.0  69       2
3   2   4  1000.0  16       1
4   2   3   750.0  77       1
count    598.000000
mean       1.235786
std        0.424844
min        1.000000
25%        1.000000
50%        1.000000
75%        1.000000
max        2.000000
Name: target, dtype: float64
No path specified. Models will be saved in: "AutogluonModels/ag-20240413_041600"
No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.
        Recommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):
        presets='best_quality'   : Maximize accuracy. Default time_limit=3600.
        presets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.
        presets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.
        presets='medium_quality' : Fast training time, ideal for initial prototyping.
Beginning AutoGluon training ...
AutoGluon will save models to "AutogluonModels/ag-20240413_041600"
=================== System Info ===================
AutoGluon Version:  1.0.0
Python Version:     3.10.6
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Thu Jan 11 04:09:03 UTC 2024
CPU Count:          12
Memory Avail:       11.96 GB / 15.59 GB (76.7%)
Disk Space Avail:   848.39 GB / 1006.85 GB (84.3%)
===================================================
Train Data Rows:    598
Train Data Columns: 4
Label Column:       target
AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).
        2 unique label values:  [2, 1]
        If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])
Problem Type:       binary
Preprocessing data ...
Selected class <--> label mapping:  class 1 = 2, class 0 = 1
        Note: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (2) vs negative (1) class.
        To explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
        Available Memory:                    12250.10 MB
        Train Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)
        Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
        Stage 1 Generators:
                Fitting AsTypeFeatureGenerator...
        Stage 2 Generators:
                Fitting FillNaFeatureGenerator...
        Stage 3 Generators:
                Fitting IdentityFeatureGenerator...
        Stage 4 Generators:
                Fitting DropUniqueFeatureGenerator...
        Stage 5 Generators:
                Fitting DropDuplicatesFeatureGenerator...
        Types of features in original data (raw dtype, special dtypes):
                ('float', []) : 1 | ['V3']
                ('int', [])   : 3 | ['V1', 'V2', 'V4']
        Types of features in processed data (raw dtype, special dtypes):
                ('float', []) : 1 | ['V3']
                ('int', [])   : 3 | ['V1', 'V2', 'V4']
        0.0s = Fit runtime
        4 features in original data used to generate 4 features in processed data.
        Train Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.02s ...
AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'
        To change this, specify the eval_metric parameter of Predictor()
Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 478, Val Rows: 120
User-specified model hyperparameters to be fit:
{
        'NN_TORCH': {},
        'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],
        'CAT': {},
        'XGB': {},
        'FASTAI': {},
        'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
        'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
        'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],
}
Fitting 13 L1 models ...
Fitting model: KNeighborsUnif ...
        0.775    = Validation score   (accuracy)
        0.06s    = Training   runtime
        0.02s    = Validation runtime
Fitting model: KNeighborsDist ...
        0.7917   = Validation score   (accuracy)
        0.01s    = Training   runtime
        0.02s    = Validation runtime
Fitting model: LightGBMXT ...
        0.7917   = Validation score   (accuracy)
        0.18s    = Training   runtime
        0.0s     = Validation runtime
Fitting model: LightGBM ...
        0.7917   = Validation score   (accuracy)
        0.11s    = Training   runtime
        0.0s     = Validation runtime
Fitting model: RandomForestGini ...
        0.8083   = Validation score   (accuracy)
        0.94s    = Training   runtime
        0.06s    = Validation runtime
Fitting model: RandomForestEntr ...
        0.8083   = Validation score   (accuracy)
        0.82s    = Training   runtime
        0.06s    = Validation runtime
Fitting model: CatBoost ...
        0.7917   = Validation score   (accuracy)
        0.42s    = Training   runtime
        0.0s     = Validation runtime
Fitting model: ExtraTreesGini ...
        0.825    = Validation score   (accuracy)
        0.78s    = Training   runtime
        0.06s    = Validation runtime
Fitting model: ExtraTreesEntr ...
        0.8167   = Validation score   (accuracy)
        0.82s    = Training   runtime
        0.06s    = Validation runtime
Fitting model: NeuralNetFastAI ...
        0.7917   = Validation score   (accuracy)
        1.86s    = Training   runtime
        0.01s    = Validation runtime
Fitting model: XGBoost ...
        0.8083   = Validation score   (accuracy)
        0.15s    = Training   runtime
        0.0s     = Validation runtime
Fitting model: NeuralNetTorch ...
        0.7917   = Validation score   (accuracy)
        0.72s    = Training   runtime
        0.01s    = Validation runtime
Fitting model: LightGBMLarge ...
        0.7833   = Validation score   (accuracy)
        0.27s    = Training   runtime
        0.01s    = Validation runtime
Fitting model: WeightedEnsemble_L2 ...
        Ensemble Weights: {'ExtraTreesGini': 0.929, 'NeuralNetFastAI': 0.071}
        0.8333   = Validation score   (accuracy)
        0.53s    = Training   runtime
        0.0s     = Validation runtime
AutoGluon training complete, total runtime = 8.12s ... Best model: "WeightedEnsemble_L2"
TabularPredictor saved. To load, use: predictor = TabularPredictor.load("AutogluonModels/ag-20240413_041600")
Loaded data from: /root/paper/mypaper_code/automl/tasks/blood-transfusion-service-center/blood_test.csv | Columns = 5 / 5 | Rows = 150 -> 150
0    1
1    1
2    1
3    1
4    1
Name: target, dtype: int64
{'accuracy': 0.7466666666666667, 'balanced_accuracy': 0.5864625687634537, 'mcc': 0.2148293977750189, 'roc_auc': 0.6591724467830663, 'f1': 0.3448275862068966, 'precision': 0.47619047619047616, 'recall': 0.2702702702702703}