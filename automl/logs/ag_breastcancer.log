   diagnosis  radius_mean  ...  symmetry_worst  dimension_worst
0          0        12.32  ...          0.2827          0.06771
1          0        10.60  ...          0.2940          0.07587
2          0        11.04  ...          0.2998          0.07881
3          0        11.28  ...          0.2102          0.06784
4          0        15.19  ...          0.2487          0.06766

[5 rows x 31 columns]
count    426.000000
mean       0.370892
std        0.483612
min        0.000000
25%        0.000000
50%        0.000000
75%        1.000000
max        1.000000
Name: diagnosis, dtype: float64
0    0
1    0
2    0
3    1
4    1
Name: diagnosis, dtype: int64
{'accuracy': 0.9790209790209791, 'balanced_accuracy': 0.9795047856845609, 'mcc': 0.9556352128340201, 'roc_auc': 0.9968789013732833, 'f1': 0.9724770642201835, 'precision': 0.9636363636363636, 'recall': 0.9814814814814815}



No path specified. Models will be saved in: "AutogluonModels/ag-20240221_090729"
No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.
        Recommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):
        presets='best_quality'   : Maximize accuracy. Default time_limit=3600.
        presets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.
        presets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.
        presets='medium_quality' : Fast training time, ideal for initial prototyping.
Beginning AutoGluon training ...
AutoGluon will save models to "AutogluonModels/ag-20240221_090729"
=================== System Info ===================
AutoGluon Version:  1.0.0
Python Version:     3.10.13
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #63~20.04.1-Ubuntu SMP Wed Nov 30 13:40:16 UTC 2022
CPU Count:          40
Memory Avail:       73.46 GB / 125.55 GB (58.5%)
Disk Space Avail:   0.60 GB / 915.32 GB (0.1%)
        WARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception.
        We recommend a minimum available disk space of 10 GB, and large datasets may require more.
===================================================
Train Data Rows:    426
Train Data Columns: 30
Label Column:       diagnosis
AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).
        2 unique label values:  [0, 1]
        If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])
Problem Type:       binary
Preprocessing data ...
Selected class <--> label mapping:  class 1 = 1, class 0 = 0
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
        Available Memory:                    75227.35 MB
        Train Data (Original)  Memory Usage: 0.10 MB (0.0% of available memory)
        Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
        Stage 1 Generators:
                Fitting AsTypeFeatureGenerator...
        Stage 2 Generators:
                Fitting FillNaFeatureGenerator...
        Stage 3 Generators:
                Fitting IdentityFeatureGenerator...
        Stage 4 Generators:
                Fitting DropUniqueFeatureGenerator...
        Stage 5 Generators:
                Fitting DropDuplicatesFeatureGenerator...
        Types of features in original data (raw dtype, special dtypes):
                ('float', []) : 30 | ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', ...]
        Types of features in processed data (raw dtype, special dtypes):
                ('float', []) : 30 | ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', ...]
        0.0s = Fit runtime
        30 features in original data used to generate 30 features in processed data.
        Train Data (Processed) Memory Usage: 0.10 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.04s ...
AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'
        To change this, specify the eval_metric parameter of Predictor()
Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 340, Val Rows: 86
User-specified model hyperparameters to be fit:
{
        'NN_TORCH': {},
        'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],
        'CAT': {},
        'XGB': {},
        'FASTAI': {},
        'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
        'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],
        'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],
}
Fitting 13 L1 models ...
Fitting model: KNeighborsUnif ...
        0.9186   = Validation score   (accuracy)
        0.02s    = Training   runtime
        0.08s    = Validation runtime
Fitting model: KNeighborsDist ...
        0.9186   = Validation score   (accuracy)
        0.04s    = Training   runtime
        0.01s    = Validation runtime
Fitting model: LightGBMXT ...
        0.9767   = Validation score   (accuracy)
        0.46s    = Training   runtime
        0.02s    = Validation runtime
Fitting model: LightGBM ...
        0.9651   = Validation score   (accuracy)
        0.42s    = Training   runtime
        0.01s    = Validation runtime
Fitting model: RandomForestGini ...
        0.9767   = Validation score   (accuracy)
        1.84s    = Training   runtime
        0.12s    = Validation runtime
Fitting model: RandomForestEntr ...
        0.9651   = Validation score   (accuracy)
        1.77s    = Training   runtime
        0.11s    = Validation runtime
Fitting model: CatBoost ...
        0.9767   = Validation score   (accuracy)
        0.71s    = Training   runtime
        0.0s     = Validation runtime
Fitting model: ExtraTreesGini ...
        0.9651   = Validation score   (accuracy)
        1.69s    = Training   runtime
        0.1s     = Validation runtime
Fitting model: ExtraTreesEntr ...
        0.9651   = Validation score   (accuracy)
        1.73s    = Training   runtime
        0.1s     = Validation runtime
Fitting model: NeuralNetFastAI ...
No improvement since epoch 4: early stopping
        0.9767   = Validation score   (accuracy)
        2.46s    = Training   runtime
        0.01s    = Validation runtime
Fitting model: XGBoost ...
        0.9651   = Validation score   (accuracy)
        0.22s    = Training   runtime
        0.0s     = Validation runtime
Fitting model: NeuralNetTorch ...
        0.9884   = Validation score   (accuracy)
        1.36s    = Training   runtime
        0.04s    = Validation runtime
Fitting model: LightGBMLarge ...
        0.9535   = Validation score   (accuracy)
        1.01s    = Training   runtime
        0.02s    = Validation runtime
Fitting model: WeightedEnsemble_L2 ...
        Ensemble Weights: {'NeuralNetTorch': 1.0}
        0.9884   = Validation score   (accuracy)
        0.69s    = Training   runtime
        0.0s     = Validation runtime
AutoGluon training complete, total runtime = 15.26s ... Best model: "WeightedEnsemble_L2"
TabularPredictor saved. To load, use: predictor = TabularPredictor.load("AutogluonModels/ag-20240221_090729")
Loaded data from: /home/ddp/nlp/github/paper/mypaper_code/automl/data/wisconsin_breast_cancer_dataset_test.csv | Columns = 31 / 31 | Rows = 143 -> 143